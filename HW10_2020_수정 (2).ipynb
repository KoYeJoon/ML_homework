{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:54:48.508891Z",
     "start_time": "2020-06-07T06:54:48.247497Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moon Jeong-Hyeon \n",
      "last updated: 2020-06-20 \n",
      "\n",
      "numpy 1.18.1\n",
      "pandas 1.0.3\n",
      "matplotlib 3.1.3\n",
      "sklearn 0.22.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Moon Jeong-Hyeon' -u -d -p numpy,pandas,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** 코딩해야할 부분을 제외하고는 수정하지 마세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.109724Z",
     "start_time": "2020-06-07T06:54:49.615474Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_sci = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.494027Z",
     "start_time": "2020-06-07T06:55:03.117550Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_, y_test_ = train_test_split(mnist_sci.data, mnist_sci.target, \n",
    "                                                    test_size = 0.1,\n",
    "                                                   shuffle = True)\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "x_train = x_train.reshape(-1,1,28,28)\n",
    "x_test = x_test.reshape(-1,1,28,28)\n",
    "\n",
    "def one_hoy_label(X):\n",
    "    T = np.zeros((X.size, 10))    \n",
    "    for idx, row in enumerate(T):\n",
    "        row[int(X[idx])] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "y_train = one_hoy_label(y_train_)\n",
    "y_test = one_hoy_label(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_CE:\n",
    "    \"\"\"\n",
    "    편의를 위해서 softmax와 crossenropy를 결합한 것입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = CE_loss(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1 에서 구현한 것을 바탕으로 CNN도 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    # masking을 해보세요\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x<=0)\n",
    "        out = x.copy()\n",
    "        out[self.mask]=0\n",
    "        return out\n",
    "    \n",
    "    # 항등항수의 미분은 자기 자신입니다. \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask]=0\n",
    "        dx = dout     \n",
    "        return dx\n",
    "class FClayer:\n",
    "    def __init__(self, W, b):  \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        # backward 를 위해서 shape을 변경할 수가 있어서 원래의 shape 저장\n",
    "        self.original_x_shape = None\n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 본인이 구현한 입력 이미지의 shape 에 따라서 조정을 해줄수도 있습니다. \n",
    "        self.original_x_shape = x.shape\n",
    "        self.x = x.reshape(x.shape[0],-1)\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "        return out\n",
    " \n",
    "    # 1차원 함수의 곱셈에 대해서 생각해보고 그것을 확장하세요 \n",
    "    # 항상 데이터의 shape에 주의 하세요\n",
    "    def backward(self, dout):\n",
    "        #print(len(self.x))\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        dx = dx.reshape(self.original_x_shape)\n",
    "        return dx\n",
    "    \n",
    "    \n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    y = exp_x / np.sum(exp_x,axis=1).reshape(-1,1)\n",
    "    y=y.T\n",
    "    return y.T \n",
    "def CE_loss(y, t):\n",
    "    delta = 1e-7\n",
    "    loss = -np.sum(t*(np.log(y+delta)))\n",
    "    return loss\n",
    "class Softmax_CE:\n",
    "    \"\"\"\n",
    "    편의를 위해서 softmax와 crossenropy를 결합한 것입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = CE_loss(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv():\n",
    "    def __init__(self, W, b, stride=1, pad=0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None   \n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # backward 의 shape 확인을 위해서 저장\n",
    "        self.x = x[:]        \n",
    "        \n",
    "        FN, C_, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        # output 출력 shape \n",
    "        self.out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        self.out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w        \n",
    "        \n",
    "        # padding\n",
    "        pad_x = np.pad(\n",
    "            x, \n",
    "            ((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \n",
    "            \"constant\", constant_values=0\n",
    "        )\n",
    "        \n",
    "\n",
    "        out = np.zeros((N, FN, out_h, out_w))        \n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-1-1 forward를 구현 하세요                                   #\n",
    "                        ######################################################################\n",
    "                        out[n,f,j,i]=np.sum(pad_x[n,:,j:j+FH,i:i+FW]*self.W[f,:,:,:])+self.b[f]\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "                        \n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = self.x.shape\n",
    "        \n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w\n",
    "        \n",
    "        # padding\n",
    "        pad_x = np.pad(\n",
    "            self.x, \n",
    "            ((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \n",
    "            \"constant\", constant_values=0\n",
    "        )\n",
    "        \n",
    "        dx = np.zeros(pad_x.shape)\n",
    "        dw = np.zeros(self.W.shape)\n",
    "        db = np.zeros(self.b.shape)\n",
    "        \n",
    "    \n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-1-2 backward 구현 하세요                                   #\n",
    "                        ######################################################################\n",
    "                        dx[n,:,j:j+FH,i:i+FW] = dx[n,:,j:j+FH,i:i+FW] + np.sum(dout[n,f,j,i]*self.W[f,:,:,:])\n",
    "                        dw[f,:,:,:] = dw[f,:,:,:] + np.sum(pad_x[n,:,j:j+FH,i:i+FW]*dout[n,f,j, i])\n",
    "                        db[f] = db[f] + dout[n,f,j,i]\n",
    "                      \n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "                        \n",
    "        # remove padding\n",
    "        dx = dx[:, :, self.pad:dx.shape[2]-self.pad, self.pad:dx.shape[3]-self.pad]\n",
    "        \n",
    "        self.db = db\n",
    "        self.dW = dw\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x[:]\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        \n",
    "        out = np.zeros((N, C, out_h, out_w))\n",
    "        for j in range(out_h):\n",
    "            for i in range(out_w):\n",
    "                ######################################################################\n",
    "                # 문제 2-2-1 forward를 구현 하세요                                   #\n",
    "                ######################################################################\n",
    "                out[:,:,j,i] = np.max(np.max(self.x[:,:,self.stride*j:self.stride*j + self.pool_h,self.stride*i:self.stride*i +self.pool_w],axis=2),axis=2)  \n",
    "                \n",
    "                ######################################################################\n",
    "                #                          END OF YOUR CODE                          #\n",
    "                ######################################################################\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        N, C, H, W = self.x.shape\n",
    "        out_h = (H-self.pool_h) // self.stride + 1\n",
    "        out_w = (W-self.pool_w) // self.stride + 1\n",
    "\n",
    "        dx = np.zeros(self.x.shape)\n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-2-2 backward를 구현 하세요                                   #\n",
    "                        ######################################################################\n",
    "                        #temp = self.x.reshape(self.x.shape[0],-1)\n",
    "                        #dx[n,c,j:j+self.pool_h,i:i+self.pool_w] = dx[n,c,j:j+self.pool_h,i:i+self.pool_w]+np.sum(temp.T*dout[n,c,j,i])\n",
    "                        dx[n,c,self.stride*j:self.stride*j + self.pool_h,self.stride*i:self.stride*i +self.pool_w] += dout[n,c,j,i]\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:19.163192Z",
     "start_time": "2020-06-07T06:55:19.146865Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        weight_init_std = 0.01\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        \n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        \n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Conv(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = MaxPooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['FClayer1'] = FClayer(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['FClayer2'] = FClayer(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = Softmax_CE()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        ######################################################################\n",
    "        #  2-3 해당 주어진 gradient 함수에 주석을 다세요                     #\n",
    "        ######################################################################\n",
    "        # forward\n",
    "        #이미지 데이터 x를 모델에 넣어서 만든 output과 softmax를 이용해 cross entropy를 구한다.\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        # dout을 1로 초기화한다.\n",
    "        dout = 1\n",
    "        #dx = (self.y - self.t) / batch_size를 통해 기울기를 구한다.\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        #layer의 value들을 저장한다.\n",
    "        layers = list(self.layers.values())\n",
    "        #backpropagation을 할 것이므로, 순차적으로 거꾸로 돌아갈 것이므로 뒤집는다.\n",
    "        layers.reverse()\n",
    "        #layers가 뒤집혔으므로, 순차적으로 거꾸로 돌아가면서 반대 방향으로 네트워크를 업데이트 한다.\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        #Conv layer의 dW, db저장\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        #FClayer1의 dW, db저장\n",
    "        grads['W2'], grads['b2'] = self.layers['FClayer1'].dW, self.layers['FClayer1'].db\n",
    "        #FClayer2의 dW, db저장\n",
    "        grads['W3'], grads['b3'] = self.layers['FClayer2'].dW, self.layers['FClayer2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:20.334140Z",
     "start_time": "2020-06-07T06:55:20.301677Z"
    }
   },
   "outputs": [],
   "source": [
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 3, 'filter_size': 3, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=16, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습이 되기전 conv layer 의 파라미터값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAABFCAYAAADuHbzJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACS0lEQVR4nO3br4pqYRSG8fUdhI2IIKL5NJPBYFXGZPMexmIXMZm8Cu/AYFKb2WIYu83JiiBThe+Ec/YkhZG1z7+X55cEXctvDw8iwzbEGA3433372wcAskDIkEDIkEDIkEDIkEDIkJB75sWFQiGWSiXXG358fLjmU7VazTV/PB7tfD4HM7MkSWI+n3ftu16vrvlUuVx277hcLucYYzWE4P7fqvfvnCoWi+4db29v5xhj9d5zT4VcKpVsMBi4DrPdbl3zqc1m45pvNpufj/P5vL28vLj2LZdL13yq2+26d8zn8/cMjmJmZrPZLJM9nU7HvSOE8PC6+GoBCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCU/dxpnL5axavXs76Jc1Gg3XfCqEkMkes5+3p/Z6PdeOyWSSyVmm02kme8zM6vW6rVYr147RaJTJWRaLRSZ7HuETGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRKe+oXI7Xaz0+nkesPdbueaT7Xbbdf8fr//fFypVKzf77v2DYdD13xqPB67d6zXazMzOxwO1mq1XLteX1/d5zEzS5Ikkz2P8IkMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCSHG+PUXh3Ays/ffd5w/6nuMsWomd11mv65N9bruPfFUyMC/iq8WkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkPADdslm1OhTsUQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test acc | 0.8858571428571429\n",
      " test acc | 0.9125714285714286\n",
      " test acc | 0.9238571428571428\n"
     ]
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "test_acc_list = []\n",
    "epochs = 3\n",
    "step = int(train_size / batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx in range(step):\n",
    "        x_batch = x_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        y_batch = y_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        grad = network.gradient(x_batch, y_batch)\n",
    "\n",
    "        # 매개변수 갱신\n",
    "        for key in network.params.keys():\n",
    "            network.params[key] -= learning_rate * grad[key]\n",
    "            \n",
    "        # 학습 경과 기록\n",
    "        loss = network.loss(x_batch, y_batch)\n",
    "\n",
    "    test_acc = network.accuracy(x_test, y_test)\n",
    "    print(\" test acc | \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 후 파라미터 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAABFCAYAAADuHbzJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACS0lEQVR4nO3br4pqYRSG8fUdhI2IIKL5NJPBYFXGZPMexmIXMZm8Cu/AYFKb2WIYu83JiiBThe+Ec/YkhZG1z7+X55cEXctvDw8iwzbEGA3433372wcAskDIkEDIkEDIkEDIkEDIkJB75sWFQiGWSiXXG358fLjmU7VazTV/PB7tfD4HM7MkSWI+n3ftu16vrvlUuVx277hcLucYYzWE4P7fqvfvnCoWi+4db29v5xhj9d5zT4VcKpVsMBi4DrPdbl3zqc1m45pvNpufj/P5vL28vLj2LZdL13yq2+26d8zn8/cMjmJmZrPZLJM9nU7HvSOE8PC6+GoBCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCU/dxpnL5axavXs76Jc1Gg3XfCqEkMkes5+3p/Z6PdeOyWSSyVmm02kme8zM6vW6rVYr147RaJTJWRaLRSZ7HuETGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRKe+oXI7Xaz0+nkesPdbueaT7Xbbdf8fr//fFypVKzf77v2DYdD13xqPB67d6zXazMzOxwO1mq1XLteX1/d5zEzS5Ikkz2P8IkMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCYQMCSHG+PUXh3Ays/ffd5w/6nuMsWomd11mv65N9bruPfFUyMC/iq8WkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkPADdslm1OhTsUQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################\n",
    "#  2-4 학습된 필터를 캡처하여 제출하세요                                      #\n",
    "######################################################################\n",
    "filter_show(network.params['W1'])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
